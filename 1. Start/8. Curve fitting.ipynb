{
 "metadata": {
  "name": "",
  "signature": "sha256:f93b628bb6783067024c7ad802b15860782f01a8a4d73edf371b7997fbe3ef75"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Curve Fitting\n",
      "\n",
      "Dana analysis often consists of fitting a model on data (frequentist approach). In astrophysics, data usually suffers from uncertainties, both statistical (e.g. limited number of photons/measurements) and systematics (e.g. instrumental noise). These have to be taken into account when modeling the noisy data.\n",
      "\n",
      "This short introduction to curve fitting will introduce a method particulartly adapted for [polynomial fitting](#Polynomial fitting) and a more general set of [optimization methods](#Scipy optimization library) that works with more complicated models."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A few necessary imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "from __future__ import print_function, division\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Polynomial fitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Polynomial fitting uses linear algebra which is implemented in `numpy` under `numpy.linalg` (see [`lstsq`](#Traditional method)). There is even a wrapper for polynomial fitting called [`polyfit`](#Polyfit)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy.linalg import lstsq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One-dimentional polynomials can easily be represented using the numpy `poly1d` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def f_poly(x, a, b, c):\n",
      "    \"\"\"Represents a*x^2 + b*x + c\"\"\"\n",
      "    poly = np.poly1d([a, b, c])\n",
      "    return poly(x)\n",
      "\n",
      "scatter = 0.5\n",
      "n_coord = 50\n",
      "p0 = (0.5, 2, -1)\n",
      "\n",
      "x = np.linspace(-5, 5, n_coord)\n",
      "y_true = f_poly(x, *p0)\n",
      "y_data = f_poly(x, *p0) + np.random.normal(scale=scatter, size=n_coord)\n",
      "# Uncertainty on the data points\n",
      "sigma = np.ones_like(y_data)*scatter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The uncertainty on the data points can be shown using the matplotlib errorbar method. Here we show the true model and the data drawn from it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# below is a dictionary that helps formatting \n",
      "# the errorbar plot method\n",
      "errdict = {'linestyle': 'o',\n",
      "           'color': 'Blue',\n",
      "           'capsize': 2,\n",
      "           'marker': 'o',\n",
      "           'markersize': 4,\n",
      "           'mec': 'Blue',\n",
      "           'mfc': 'white'}\n",
      "\n",
      "plt.errorbar(x, y_data, sigma, label='Noisy data', **errdict)\n",
      "plt.plot(x, y_true, ls='-', color='Green', label='True model')\n",
      "plt.legend(loc=0, frameon=False)\n",
      "plt.title('Polynomial fitting - Noisy sample')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Traditional method"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The line equation $$y = ax^2 + bx + c$$ can be rewritten in a matrix product form such as \n",
      "$$ y = \\mathbf{V p}$$ where \n",
      "$$\\mathbf{V} = \\begin{pmatrix}x^2 &x &1 \\end{pmatrix} \n",
      "\\quad \\text{and} \\quad \n",
      "\\mathbf{p} = \\begin{pmatrix}a\\\\b\\\\c\\end{pmatrix} .$$\n",
      "The matrix $\\mathbf{V}$ is called a Vandermonde matrix and can easily be created in numpy using the numpy `vander` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The vander method is provided with the axis vector \n",
      "# and the dimension of the desired matrix\n",
      "V = np.vander(x, 3)\n",
      "\n",
      "# alternatively, V can be constructed using vstack\n",
      "# V = np.vstack([x**2, x, np.ones_like(x)]).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Solve the linear matrix equation by minimizing the Euclidean 2-norm $$\\left\\|y - \\mathbf{V p}\\right\\|^2 .$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p_lstsq = np.linalg.lstsq(V, y_data)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x, y_true, ls=':', color='Green', label='True model')\n",
      "plt.errorbar(x, y_data, sigma, label='Noisy data', **errdict)\n",
      "plt.plot(x, f_poly(x, *p_lstsq) , ls='-', color='Red', label='Fit')\n",
      "plt.legend(loc=0, frameon=False)\n",
      "plt.title('Polynomial fitting - numpy lstsq')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Polyfit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Numpy provided a wrapper for the overall procedure called `polyfit`. The weight associated with data points can be input using the `w=` keyword.\n",
      "\n",
      "**NOTE:** The polynomial coefficients output by `polyfit` are conveniently ordered to input the `poly1d` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weigths = 1 / sigma**2\n",
      "p_pfit, pfit_cov = np.polyfit(x, y_data, 2, w=sigma, cov=True)\n",
      "p_pfit_err = np.sqrt(np.diag(pfit_cov))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"True parameters:\", *p0, sep=\"\\t\")\n",
      "print(\"Fitted parameters:\", *(\"{:.2f} +/- {:.2f}\".format(p, p_err) for p, p_err in zip(p_pfit, p_pfit_err)), sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x, y_true, ls=':', color='Green', label='True model')\n",
      "plt.errorbar(x, y_data, sigma, label='Noisy data', **errdict)\n",
      "plt.plot(x, f_poly(x, *p_pfit) , ls='-', color='Red', label='Fit')\n",
      "plt.legend(loc=0, frameon=False)\n",
      "plt.title('Polynomial fitting - numpy polyfit')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scipy optimization library"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Advanced optimization tools for non polynomial functions can be found in the **Scipy** library under `scipy.optimize`. This tutorial will focus on two methods: [curve_fit](#Curve fit) and the more general [leastsq](#Least square) method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.optimize import curve_fit, leastsq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We define a model `f` that is a decreasing exponential curve and we draw noisy data from it using gaussian random noise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def f_curve(x, a, b, c):\n",
      "    return a * np.exp(-b*x) + c\n",
      "\n",
      "scatter = 0.1\n",
      "n_coord = 50\n",
      "p0 = (2, 1.5, -3)\n",
      "\n",
      "x = np.linspace(0, 5, n_coord)\n",
      "y_true = f_curve(x, *p0)\n",
      "y_data = f_curve(x, *p0) + np.random.normal(scale=scatter, size=n_coord)\n",
      "sigma = np.ones_like(y_data)*scatter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The uncertainty on the data points can be shown using the matplotlib `errorbar` method. Here we show the true model and the data drawn from it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x, y_true, ls='-', color='Green', label='True model')\n",
      "plt.errorbar(x, y_data, sigma, label='Noisy data', **errdict)\n",
      "plt.legend(loc=1, frameon=False)\n",
      "plt.title('General curve fitting - Noisy sample')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Leastsq"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scipy's `leastsq` is a non-linear least square minimizer. It must be called on a cost function that takes the parameters as input (all other arguments should be called using keyword `args`)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def err_func(p, x, y, sig):\n",
      "    return (y - f_curve(x, *p)) / sig\n",
      " \n",
      "p_guess = (1, 1, 1)\n",
      "p_leastsq, success = leastsq(err_func, p_guess, args=(x, y_data, sigma))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x, y_true, ls=':', color='Green', label='True model')\n",
      "plt.errorbar(x, y_data, sigma, label='Noisy data', **errdict)\n",
      "plt.plot(x, f_curve(x, *p_leastsq) , ls='-', color='Red', label='Fit')\n",
      "plt.legend(loc=1, frameon=False)\n",
      "plt.title('General curve fitting - scipy leastsq')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Curve fit"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While scipy's `leastsq` method is very powerful and contains lots of options, it might sometimes be tedious to have to define the cost function first. This is why they also provided a wrapper called `curve_fit`, that can be called in a straightforward way simply providing the function, the coordinates and the data (and a few optional keywords)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p_cfit, cfit_cov = curve_fit(f_curve, x, y_data, sigma=sigma, p0=p_guess)\n",
      "p_cfit_err = np.sqrt(np.diag(cfit_cov))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"True parameters:\", *p0, sep=\"\\t\")\n",
      "print(\"Fitted parameters:\", *(\"{:.2f} +/- {:.2f}\".format(p, p_err) for p, p_err in zip(p_cfit, p_cfit_err)), sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x, y_true, ls=':', color='Green', label='True model')\n",
      "plt.errorbar(x, y_data, sigma, label='Noisy data', **errdict)\n",
      "plt.plot(x, f_curve(x, *p_cfit) , ls='-', color='Red', label='Fit')\n",
      "plt.legend(loc=1, frameon=False)\n",
      "plt.title('General curve fitting - scipy curvefit')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercises"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. Modify the `scatter` value to see the impact on the fitted parameter and their error ;\n",
      "2. Lower the number of coordinate values (`n_coord`) until you see that the fitting process does not converge or is undetermined."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
